# AI模型Token限制总结 (2025年更新版)

## 🎯 90%安全边际策略

为了确保翻译结果不会超出输出token限制，我们使用90%的安全边际。这是因为：
- 翻译通常比原文长（特别是英文 → 中文/日文/韩文）
- 不同语言的token密度差异
- 确保翻译质量不会因截断而受影响

## 📊 2025年最新模型Token分配

### OpenAI 模型 (2025最新)
| 模型 | 上下文窗口 | 输出限制 | 90%安全输出 | 批次建议 | 特点 |
|------|------------|----------|-------------|----------|------|
| **GPT-4.1** | 1M | 4,096 | 3,686 | 50,000 | 最新模型，程式碼能力大幅提升 |
| **GPT-4.1 Mini** | 1M | 4,096 | 3,686 | 50,000 | 延遲減半，成本降低83% |
| **GPT-4.1 Nano** | 1M | 4,096 | 3,686 | 50,000 | 最快最便宜，1M上下文 |
| GPT-4o | 128K | 4,096 | 3,686 | 15,000 | 多模態模型 |
| GPT-4o Mini | 128K | 4,096 | 3,686 | 15,000 | 平衡效能與成本 |

### Claude 模型 (2025最新)
| 模型 | 上下文窗口 | 输出限制 | 90%安全輸出 | 批次建議 | 特點 |
|------|------------|----------|-------------|----------|------|
| **Claude Opus 4.1** | 1M | 8,192 | 7,372 | 50,000 | 最智能，2025年8月發布 |
| **Claude Sonnet 4** | 1M | 8,192 | 7,372 | 50,000 | 可處理75,000行程式碼 |
| **Claude 3.7 Sonnet** | 200K | 128,000 | 115,200 | 25,000 | 混合推理模型，超大輸出 |
| Claude 3.5 Sonnet | 200K | 8,192 | 7,372 | 25,000 | 業界領先智能水平 |
| Claude 3.5 Haiku | 200K | 8,192 | 7,372 | 25,000 | 最具成本效益 |

### Gemini 模型 (2025最新)
| 模型 | 上下文窗口 | 輸出限制 | 90%安全輸出 | 批次建議 | 特點 |
|------|------------|----------|-------------|----------|------|
| **Gemini 2.5 Pro** | 1M(→2M) | 8,192 | 7,372 | 50,000 | 最先進思考模型 |
| **Gemini 2.5 Flash** | 1M | 8,192 | 7,372 | 50,000 | 效率提升20-30% |
| **Gemini 2.0 Pro** | 2M | 8,192 | 7,372 | 50,000 | 最強編碼性能 |
| Gemini 2.0 Flash | 1M | 8,192 | 7,372 | 50,000 | 原生工具使用 |
| Gemini 1.5 Pro | 2M | 8,192 | 7,372 | 50,000 | 可處理2小時影片 |

### OpenRouter 免費模型 (2025最新，每日50次)
| 模型 | 上下文窗口 | 輸出限制 | 90%安全輸出 | 批次建議 | 特點 |
|------|------------|----------|-------------|----------|------|
| **Llama 4 Maverick** | 256K | 8,192 | 7,372 | 25,000 | Meta最新Llama 4 |
| **Llama 4 Scout** | 512K | 8,192 | 7,372 | 50,000 | 探索級模型 |
| **DeepSeek R1** | 128K | 8,192 | 7,372 | 15,000 | 推理優化模型 |
| Gemma 3 27B | 128K | 8,192 | 7,372 | 15,000 | Google最新27B模型 |
| Llama 3.3 70B | 128K | 8,192 | 7,372 | 15,000 | 性能接近405B |
| Gemini 2.5 Pro Exp | 1M | 8,192 | 7,372 | 50,000 | Google實驗模型 |

### Ollama 本地模型 (2025最新，需手動配置上下文)
| 模型 | 上下文窗口 | 輸出限制 | 90%安全輸出 | 批次建議 | 特點 |
|------|------------|----------|-------------|----------|------|
| **GPT-OSS 120B** | 128K | 8,192 | 7,372 | 15,000 | OpenAI開源模型 |
| **DeepSeek R1** | 128K | 8,192 | 7,372 | 15,000 | 推理優化本地版 |
| **Llama 3.3 70B** | 128K | 8,192 | 7,372 | 15,000 | 高性能低記憶體需求 |
| Llama 3.2 Vision 90B | 128K | 8,192 | 7,372 | 15,000 | 圖文理解能力 |
| Gemma 3 27B | 128K | 8,192 | 7,372 | 15,000 | 滑動窗口注意力 |
| Mistral Small 3.1 | 128K | 8,192 | 7,372 | 15,000 | 與NVIDIA合作優化 |

## 🚀 优化效果

### 翻译扩展考虑
- **英文 → 中文**: 通常增加20-40%长度
- **英文 → 日文**: 通常增加30-50%长度  
- **英文 → 韩文**: 通常增加25-45%长度
- **中文 → 英文**: 通常减少10-20%长度

### 安全边际效益
1. **避免截断**: 90%边际确保翻译完整
2. **提高稳定性**: 减少API错误
3. **更好的用户体验**: 无需重试失败的翻译
4. **适应语言差异**: 处理不同语言的token密度变化

## ⚙️ 实现细节

```javascript
// 计算安全输出token数量
const safeOutputTokens = Math.floor(maxOutputTokens * 0.9);

// 为Gemini特别处理硬限制
if (api === 'gemini') {
    outputTokens = Math.min(outputTokens, 7372); // 90% of 8192
}
```

这样的设计确保所有翻译都能在token限制内完成，特别是解决了你遇到的Gemini "maxOutputTokens value of 39321 but the supported range is from 1 to 8193" 错误。